<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ljzsdut</title><link>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/</link><description>Recent content on ljzsdut</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/01-Telegraf%E5%AF%B9%E6%AF%94Exporter%E7%9A%84%E4%BC%98%E5%8A%BF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/01-Telegraf%E5%AF%B9%E6%AF%94Exporter%E7%9A%84%E4%BC%98%E5%8A%BF/</guid><description>转载
Prometheus的生态中，Exporter扮演了重要的角色。对于“知名”应用程序，服务器或数据库，Prometheus官方提供了足够多的Exporters。这也是Prometheus监视目标的主要方式。
当然当你需要监控的中间件或是数据库类型比较少的时候，并没有什么问题。
但是当你的监控系统扩展到一定规模的时候，你可能需要维护几百种exporter，数量甚至是到了几万个的时候，这时候你大多的精力浪费在维护和升级exporter，甚至是管理他们的部署。
Exporters 如果没有深切体会，请看下面官方包括社区提供的诸多Exporters吧！
Databases Aerospike exporter ClickHouse exporter Consul exporter(official) Couchbase exporter CouchDB exporter ElasticSearch exporter EventStore exporter Memcached exporter(official) MongoDB exporter MSSQL server exporter MySQL router exporter MySQL server exporter(official) OpenTSDB Exporter Oracle DB Exporter PgBouncer exporter PostgreSQL exporter Presto exporter ProxySQL exporter RavenDB exporter Redis exporter RethinkDB exporter SQL exporter Tarantool metric library Twemproxy Hardware related apcupsd exporter BIG-IP exporter Collins exporter Dell Hardware OMSA exporter IBM Z HMC exporter IoT Edison exporter IPMI exporter knxd exporter Modbus exporter Netgear Cable Modem Exporter Netgear Router exporter Node/system metrics exporter(official) NVIDIA GPU exporter ProSAFE exporter Ubiquiti UniFi exporter Issue trackers and continuous integration Bamboo exporter Bitbucket exporter Confluence exporter Jenkins exporter JIRA exporter Messaging systems Beanstalkd exporter EMQ exporter Gearman exporter IBM MQ exporter Kafka exporter NATS exporter NSQ exporter Mirth Connect exporter MQTT blackbox exporter RabbitMQ exporter RabbitMQ Management Plugin exporter RocketMQ exporter Solace exporter Storage Ceph exporter Ceph RADOSGW exporter Gluster exporter Hadoop HDFS FSImage exporter Lustre exporter ScaleIO exporter HTTP Apache exporter HAProxy exporter(official) Nginx metric library Nginx VTS exporter Passenger exporter Squid exporter Tinyproxy exporter Varnish exporter WebDriver exporter APIs AWS ECS exporter AWS Health exporter AWS SQS exporter Azure Health exporter BigBlueButton Cloudflare exporter DigitalOcean exporter Docker Cloud exporter Docker Hub exporter GitHub exporter InstaClustr exporter Mozilla Observatory exporter OpenWeatherMap exporter Pagespeed exporter Rancher exporter Speedtest exporter Tankerkönig API Exporter Logging Fluentd exporter Google&amp;rsquo;s mtail log data extractor Grok exporter 此时本文的主角Telegraf 该出场了。</description></item><item><title/><link>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/02-telegraf%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/02-telegraf%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/</guid><description>https://blog.csdn.net/lulongji2035/article/details/109029677
https://www.cnblogs.com/boshen-hzb/p/9674087.html
概述 &amp;ldquo;Telegraf is an agent for collecting, processing, aggregating, and writing metrics.
Design goals are to have a minimal memory footprint with a plugin system so that developers in the community can easily add support for collecting metrics.&amp;rdquo;
在Prometheus系统中，Telegraf充当了Metric exporter的功能，得益于Telegraf强大的插件架构，可以实现各式各样的数据采集模式（不管是作为client端，还是server端），然后输出到后端的数据存储（比如Prometheus)。
Telegraf官网：https://www.influxdata.com/time-series-platform/telegraf/
官方文档：https://docs.influxdata.com/telegraf/v1.21/
Telegraf GitHub代码仓库地址: https://github.com/influxdata/telegraf
Telegraf 是 InfluxData 开源的一款采集器，可以采集操作系统、各种中间件的监控指标，采集目标列表：https://github.com/influxdata/telegraf/tree/master/plugins/inputs 看起来是非常丰富，Telegraf是一个大一统的设计，即一个二进制可以采集CPU、内存、mysql、mongodb、redis、snmp等，不像Prometheus的exporter，每个监控对象一个exporter，管理起来略麻烦。一个二进制分发起来确实比较方便。
但是，Telegraf主要是为InfluxDB设计的，采集的很多监控指标，标签部分可能不固定，比如net_response这个采集input插件，在成功的时候，会附一个标签：result=success，超时的时候，又会变成：result=timeout，对于InfluxDB的存储模型和使用方式来说，这样做是没问题的，但是大部分时序库都不喜欢这个玩法，时序库更喜欢标签是稳态的，因为标签是监控数据的唯一标识，如果标签发生变化，就相当于是新的监控数据了，这就有点恶心了。好在Telegraf提供了一些配置机制，可以把部分标签给干掉，只留那些稳定的标签，这样就舒服多了。上面这段话不理解也没关系，后面慢慢就有感触了。
调研Telegraf是希望把Telegraf作为夜莺的一种采集端程序使用，夜莺自身是有一个Agentd的，但是支持的采集内容有限，v5版本开始，拥抱Prometheus生态，故而可以和Prometheus生态的各类Exporter协同，但是Exporter是每类监控对象一个，不太方便管理，另外就是Exporter是pull模型，夜莺的设计中，会对监控对象做额外的产品支持，需要从监控数据中解析出监控对象，pull模型的exporter，直接由Prometheus进程来采集，数据压根就不会流经夜莺的服务端，所以夜莺无法感知到这些数据，更别提解析这些数据了。Telegraf有很多output插件，比如可以把采集到的监控数据输出给InfluxDB、OpenTSDB、Prometheus、Kafka等，夜莺只要实现比如OpenTSDB的接收数据的HTTP接口，就可以接收Telegraf推送的数据啦，这样数据就会先流经夜莺的服务端，在服务端做解析，提取监控对象，做一些Nodata判断等，与夜莺的生态良好的集成到了一起。
架构 TICK：
安装 Telegraf的安装，非常简单，直接从官网下载编译好的二进制即可，或者自己编译也OK，比如64位Linux环境下，可以从这里下载：https://dl.influxdata.com/telegraf/releases/telegraf-1.20.2linuxamd64.tar.gz
下载之后，解压缩，看到如下目录结构：usr/bin/telegraf是二进制，etc/telegraf/telegraf.conf是配置文件，usr/lib下还给准备好了service文件，便于用systemd托管，如何作为后台程序去运行，看你自己癖好了，这是Linux基础知识，这里不再赘述。
├── etc │ ├── logrotate.d │ │ └── telegraf │ └── telegraf │ ├── telegraf.</description></item><item><title/><link>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/03-CPUMEMDISKIO%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87%E9%87%87%E9%9B%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/03-CPUMEMDISKIO%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87%E9%87%87%E9%9B%86/</guid><description>Telegraf大家有了基本了解了，但是能否用好，未必喽，今天我着重调研了一下Telegraf对CPU、内存、硬盘相关指标的采集，大部分指标还算容易理解，硬盘IO相关的有点麻烦，好，下面开始介绍。
CPU CPU相关的指标比较简单，配置也比较简单，在inputs.cpu这个section，具体如下：
# Read metrics about cpu usage [[inputs.cpu]] ## Whether to report per-cpu stats or not percpu = true ## Whether to report total system cpu stats or not totalcpu = true ## If true, collect raw CPU time metrics collect_cpu_time = false ## If true, compute and report the sum of all non-idle CPU states report_active = false percpu默认设置为true，表示每个core都采集，建议维持默认配置，totalcpu默认为true，表示采集整体情况，平时配置告警策略就靠这个呢，所以要维持默认配置true，collect_cpu_time表示采集cpu耗费的时间，因为已经采集了各种percent指标了，time相关的感觉没有必要，可以不用打开，维持false配置，report_active相当于要采集cpu使用率，但是默认是false，建议改成true，有些人还是习惯用util的视角看待cpu使用情况。
MEM 内存相关的指标更简单，默认配置里啥都没有，如下：
[[inputs.mem]] # no configuration 看来作者觉得内存相关的指标没啥需要配置的。具体采集的时候，就是把/proc/meminfo中的数据都拿出来解析上报了，就这样就好，没啥要改的，如果觉得有些指标不想上报，这里介绍给大家一个技巧，每个input插件下都可以配置一些通用的过滤规则，过滤field或者tag，比如这里我不想采集inactive这个指标，那可以这么配置： 看来作者觉得内存相关的指标没啥需要配置的。具体采集的时候，就是把/proc/meminfo中的数据都拿出来解析上报了，就这样就好，没啥要改的，如果觉得有些指标不想上报，这里介绍给大家一个技巧，每个input插件下都可以配置一些通用的过滤规则，过滤field或者tag，比如这里我不想采集inactive这个指标，那可以这么配置：</description></item><item><title/><link>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/04-kernelsystemprocesses%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87%E9%87%87%E9%9B%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/04-kernelsystemprocesses%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87%E9%87%87%E9%9B%86/</guid><description>kernel kernel相关的指标，Telegraf采集的不太多，相关配置和采集内容如下：
# Get kernel statistics from /proc/stat [[inputs.kernel]] # no configuration # Output: kernel,host=10-255-0-34 boot_time=1624622463i,context_switches=15118293984i,entropy_avail=3117i,interrupts=9688656581i,processes_forked=64968689i 1636203352000000000 保持这个配置不动即可
system system相关的指标，要指定一下配置，把uptime_format这个field给干掉，这个内容是个字符串，Prom生态不支持，配置如下：
# Read metrics about system load &amp;amp; uptime [[inputs.system]] ## Uncomment to remove deprecated metrics. fielddrop = [&amp;#34;uptime_format&amp;#34;] system相关的指标，会采集load1、load5、load15，有些朋友可能希望这个值除以CPU核数，得到平均每个CPU的负载，在Prom生态也比较简单：
system_load1 / system_n_cpus processes processes相关的指标，主要是采集了系统的进程总数情况，有多少僵尸进程、多少running、多少sleeping等，没有额外配置项：
# Get the number of processes and group them by status [[inputs.processes]] # no configuration 建议processes_total这个指标要配置告警，比如某个cron写挫了，结束不了但是每个周期都会新建，就会造成系统中进程过多。大家可以采集一下看看自己的系统的情况，取平均total，乘以2作为阈值，后面再逐步治理。</description></item><item><title/><link>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/05-%E6%9C%AC%E5%9C%B0%E7%AB%AF%E5%8F%A3%E7%9B%91%E6%8E%A7%E8%BF%9C%E7%A8%8BTCP%E6%8E%A2%E6%B5%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/05-%E6%9C%AC%E5%9C%B0%E7%AB%AF%E5%8F%A3%E7%9B%91%E6%8E%A7%E8%BF%9C%E7%A8%8BTCP%E6%8E%A2%E6%B5%8B/</guid><description>夜莺v4版本中有个端口监控功能，我们来看一下Telegraf如何实现这个功能。遍历了一下Telegraf的input plugin列表，看起来可以用net_response这个plugin来实现。该plugin配置如下：
# # Collect response time of a TCP or UDP connection # [[inputs.net_response]] # ## Protocol, must be &amp;#34;tcp&amp;#34; or &amp;#34;udp&amp;#34; # ## NOTE: because the &amp;#34;udp&amp;#34; protocol does not respond to requests, it requires # ## a send/expect string pair (see below). # protocol = &amp;#34;tcp&amp;#34; # ## Server address (default localhost) # address = &amp;#34;localhost:80&amp;#34; # # ## Set timeout # # timeout = &amp;#34;1s&amp;#34; # # ## Set read timeout (only used if expecting a response) # # read_timeout = &amp;#34;1s&amp;#34; # # ## The following options are required for UDP checks.</description></item><item><title/><link>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/06-PING%E7%9B%91%E6%8E%A7%E8%BF%9B%E7%A8%8B%E7%9B%91%E6%8E%A7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/06-PING%E7%9B%91%E6%8E%A7%E8%BF%9B%E7%A8%8B%E7%9B%91%E6%8E%A7/</guid><description>本篇介绍两个采集插件，ping和procstat。ping监控就是用于远程探测的，年底夜莺v5最终版会内置nodata的处理逻辑，对机器的监控就不用ping了，不过有的时候，有些机器没法安装agent，这种情况可能就要考虑ping监控了。procstat主要有两个功能，一个是采集进程个数，比如nginx这种多进程模型，会采集总的进程数量，同时对每个单一进程，会采集进程相关的cpu、内存使用情况以及一些资源限制信息等。
ping ping插件的默认配置如下：
# # Ping given url(s) and return statistics # [[inputs.ping]] # ## Hosts to send ping packets to. # urls = [&amp;#34;example.org&amp;#34;] # # ## Method used for sending pings, can be either &amp;#34;exec&amp;#34; or &amp;#34;native&amp;#34;. When set # ## to &amp;#34;exec&amp;#34; the systems ping command will be executed. When set to &amp;#34;native&amp;#34; # ## the plugin will send pings directly. # ## # ## While the default is &amp;#34;exec&amp;#34; for backwards compatibility, new deployments # ## are encourag</description></item><item><title/><link>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/07-Telegraf%E6%8F%92%E4%BB%B6%E8%AE%BE%E8%AE%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://note.ljzsdut.com/%E4%BA%91%E5%8E%9F%E7%94%9F/Prometheus/Telegraf/07-Telegraf%E6%8F%92%E4%BB%B6%E8%AE%BE%E8%AE%A1/</guid><description>Telegraf 是 InfluxData 公司开源的一款十分流行的指标采集软件，在 GiHub 已有上万 Star。其借助社区的力量，拥有了多达 200 余种采集插件以及 40 余种导出插件，几乎覆盖了所有的监控项，例如机器监控、服务监控甚至是硬件监控。
架构设计 Pipeline 并发编程 在 Go 中，Pipeline 并发编程模式是一种常用的并发编程模式。简单来说，其整体上是由一系列阶段（stage），每个 stage 由一组运行着相同函数的 goroutine 组成，且各个 stage 之间由 channel 相互连接。
在每个阶段中，goroutine 负责以下事宜：
通过入口 channel，接收上游 stage 产生的数据。 处理数据，例如格式转换、数据过滤聚合等。 通过出口 channel，发送处理后的数据到下游 stage。 其中，每个 stage 都同时拥有一个或多个出口、入口 channel，除了第一个和最后一个 stage，其分别只有出口 channel 和入口 channel。
Telegraf 中的实现 Telegraf 采用了这种编程模式，其主要有 4 个 stage，分别为 Inputs、Processors、Aggregators 和 Outputs。
Inputs：负责采集原始监控指标，包括主动采集和被动采集。 Processors：负责处理 Inputs 收集的数据，包括去重、重命名、格式转换等。 Aggregators：负责聚合 Processors 处理后的数据，并对聚合后的数据计算。 Outputs：负责接收处理 Processors 或 Aggregators 输出的数据，并导出到其他媒介，例如文件、数据库等。 且它们彼此之间也是由 channel 相互链接的，其架构图如下所示：
可以看到，其整体上采用的就是 pipeline 并发编程模式，我们简单介绍下它的运作机制：</description></item></channel></rss>