<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ljzsdut</title><link>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/</link><description>Recent content on ljzsdut</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/00-ovs%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/00-ovs%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/</guid><description>概述 Open vSwitch是一个高质量的、多层虚拟交换机，使用开源Apache2.0许可协议，由Nicira Networks开发，主要实现代码为可移植的C代码。它的目的是让大规模网络自动化可以通过编程扩展,同时仍然支持标准的管理接口和协议（例如NetFlow, sFlow, SPAN, RSPAN, CLI, LACP, 802.1ag）。此外,它被设计位支持跨越多个物理服务器的分布式环境，类似于VMware的vNetwork分布式vswitch或Cisco Nexus 1000 V。Open vSwitch支持多种linux 虚拟化技术，包括Xen/XenServer， KVM和irtualBox。当前最新代码包主要包括以下模块和特性：
ovs-vswitchd 主要模块，实现switch的daemon，包括一个支持流交换的Linux内核模块； ovsdb-server 轻量级数据库服务器，提供ovs-vswitchd获取配置信息； ovs-brcompatd 让ovs-vswitch替换Linuxbridge，包括获取bridge ioctls的Linux内核模块； ovs-dpctl 用来配置switch内核模块； 一些Scripts and specs 辅助OVS安装在Citrix XenServer上，作为默认switch；
ovs-vsctl 查询和更新ovs-vswitchd的配置； ovs-appctl 发送命令消息，运行相关daemon； ovsdbmonitor GUI工具，可以远程获取OVS数据库和OpenFlow的流表。 此外，OVS也提供了支持OpenFlow的特性实现，包括
ovs-openflowd：一个简单的OpenFlow交换机； ovs-controller：一个简单的OpenFlow控制器； ovs-ofctl 查询和控制OpenFlow交换机和控制器； ovs-pki ：OpenFlow交换机创建和管理公钥框架； ovs-tcpundump：tcpdump的补丁，解析OpenFlow的消息； 内核模块实现了多个“数据路径”（类似于网桥），每个都可以有多个“vports”（类似于桥内的端口）。每个数据路径也通过关联一下流表（flow table）来设置操作，而这些流表中的流都是用户空间在报文头和元数据的基础上映射的关键信息，一般的操作都是将数据包转发到另一个vport。当一个数据包到达一个vport，内核模块所做的处理是提取其流的关键信息并在流表中查找这些关键信息。当有一个匹配的流时它执行对应的操作。如果没有匹配，它会将数据包送到用户空间的处理队列中（作为处理的一部分，用户空间可能会设置一个流用于以后碰到相同类型的数据包可以在内核中执行操作）。
在基于Linux内核的系统上，应用最广泛的还是系统自带的虚拟交换机Linux Bridge，它是一个单纯的基于MAC地址学习的二层交换机，简单高效，但同时缺乏一些高级特性，比如OpenFlow,VLAN tag,QOS,ACL,Flow等，而且在隧道协议支持上，Linux Bridge只支持vxlan，OVS支持gre/vxlan/IPsec等，这也决定了OVS更适用于实现SDN技术
OVS支持以下features
支持NetFlow, IPFIX, sFlow, SPAN/RSPAN等流量监控协议 精细的ACL和QoS策略 可以使用OpenFlow和OVSDB协议进行集中控制 Port bonding，LACP，tunneling(vxlan/gre/Ipsec) 适用于Xen，KVM，VirtualBox等hypervisors 支持标准的802.1Q VLAN协议 基于VM interface的流量管理策略 支持组播功能 flow-caching engine(datapath模块) OVS架构 先看下OVS整体架构，用户空间主要组件有数据库服务ovsdb-server和守护进程ovs-vswitchd。kernel中是datapath内核模块。最上面的Controller表示OpenFlow控制器，控制器与OVS是通过OpenFlow协议进行连接，控制器不一定位于OVS主机上，下面分别介绍图中各组件</description></item><item><title/><link>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/00-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/00-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/</guid><description>netns与veth netns：只是隔离了network资源，对其他namespace资源不进行隔离，所以宿主机上能使用的命令，netns内部也能使用。网络资源的隔离，包括网络设备、IPv4以及IPv6地址、IP路由表、防火墙、/proc/net、/sys/class/net以及套接字等。
veth：veth设备是成对出现的，两端连接两个设备，一个设备收到的数据发送请求后，会将数据发送到另一个设备上去。相当一根网线（或网线+网卡），网线两端的网卡也可以设置IP，有些时候也不设置网卡IP而是只起到连接线的作用，比如连接到二层设备网桥（交换机）的port上。
实验：在宿主机上创建2个netns，然后使用veth联通两个netns。测试两个netns是否可ping通
#创建名称空间netns1和netns2 [root@OS-network-1 ~]# ip netns add netns1 [root@OS-network-1 ~]# ip netns add netns2 [root@OS-network-1 ~]# ip netns list netns2 netns1 #创建veth设备 [root@OS-network-1 ~]# ip link add veth1.1 type veth peer name veth1.2 [root@OS-network-1 ~]# ip link show 1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 link/ether 00:1c:42:6c:b4:ed brd ff:ff:ff:ff:ff:ff 3: veth1.</description></item><item><title/><link>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/01-LinuxBridge%E5%AE%9E%E7%8E%B0%E5%8D%95%E5%AE%BF%E4%B8%BB%E6%9C%BA%E4%B8%8A%E5%A4%9A%E4%B8%AA%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%80%9A%E4%BF%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/01-LinuxBridge%E5%AE%9E%E7%8E%B0%E5%8D%95%E5%AE%BF%E4%B8%BB%E6%9C%BA%E4%B8%8A%E5%A4%9A%E4%B8%AA%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%80%9A%E4%BF%A1/</guid><description>虚拟机访问外网 拓扑图 br-ex是一个物理桥，与物理网卡绑定；采用linux网桥实现。作用是为宿主机内的虚拟机提供网络出口 br-in是一个虚拟桥，采用linux网桥实现。作用是连接虚拟机，提供虚拟机间通信的二层设备 路由器+DHCP：路由器和DHCP服务器都是在netns中实现，在该netns中打开内核转发并配置snat规则；dnsmasq提供dchp功能 vmX：虚拟机，使用qemu-kvm提供虚拟化。 veth：veth设备提供设备间连接 实现功能 1、vm间可以相互访问
2、vm可以访问外网
3、DHCP自动为vm分配IP
4、实现功能的主要设备：brctl网桥+netns
实验 1、创建物理桥br-ex #创建网桥br-ex [root@OS-network-1 ~]# brctl addbr br-ex [root@OS-network-1 ~]# ip a 1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:1c:42:6c:b4:ed brd ff:ff:ff:ff:ff:ff inet 10.</description></item><item><title/><link>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/02-ovs%E6%A1%A5%E4%B8%8EVLAN/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/02-ovs%E6%A1%A5%E4%B8%8EVLAN/</guid><description>概述 openvswitch相关介绍 ovs-vswitchd：OVS守护进程，OVS的核心部件，实现交换功能，和Linux内核兼容模块一起，实现基于流的交换（flow-based switching）。它和上层 controller 通信遵从 OPENFLOW 协议，它与 ovsdb-server 通信使用 OVSDB 协议，它和内核模块通过netlink通信，它支持多个独立的 datapath（网桥），它通过更改flow table 实现了绑定和VLAN等功能。
ovsdb-server：轻量级的数据库服务，主要保存了整个OVS 的配置信息，包括接口啊，交换内容，VLAN啊等等。ovs-vswitchd 会根据数据库中的配置信息工作。它于 manager 和 ovs-vswitchd 交换信息使用了OVSDB(JSON-RPC)的方式。
ovs-dpctl：一个工具，用来配置交换机内核模块，可以控制转发规则。
ovs-vsctl：主要是获取或者更改ovs-vswitchd 的配置信息，此工具操作的时候会更新ovsdb-server 中的数据库。
ovs-appctl：主要是向OVS 守护进程发送命令的，一般用不上。
ovsdbmonitor：GUI 工具来显示ovsdb-server 中数据信息。
ovs-controller：一个简单的OpenFlow 控制器
ovs-ofctl：用来控制OVS 作为OpenFlow 交换机工作时候的流表内容。
参考资料：
https://blog.csdn.net/tantexian/article/details/46707175（https://max.book118.com/html/2018/0502/164325096.shtm）
ovs安装 cat &amp;gt; /etc/yum.repos.d/openstack-rocky.repo &amp;lt;&amp;lt;EOF [openstack] name=opentack baseurl=https://mirrors.aliyun.com/centos/7/cloud/x86_64/openstack-rocky/ gpgcheck=0 [Virt] name=CentOS-$releasever - Base baseurl=https://mirrors.aliyun.com/centos/7/virt/x86_64/kvm-common/ gpgcheck=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 EOF [root@OS-network-1 ~]# yum install -y openvswitch [root@OS-network-1 ~]# ovs-vsctl -V ovs-vsctl (Open vSwitch) 2.11.0 DB Schema 7.</description></item><item><title/><link>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/03-ovs%E6%A1%A5%E4%B8%8EGRE%E9%9A%A7%E9%81%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/03-ovs%E6%A1%A5%E4%B8%8EGRE%E9%9A%A7%E9%81%93/</guid><description>试验拓补图 说明：由于node2和node3上的网卡都是内部网卡，不能访问外网，为了使他们能够访问repo安装软件，会将node2和node3的管理网卡的网关指向node1。而node1会开启内核转发和SNAT规则，以作为网关使用。
环境准备 1、配置Host1作为网关 # 开启内核转发 # 临时生效：sysctl -w net.ipv4.ip_forward=1 [root@centos7-1 ~]# vi /etc/sysctl.conf # sysctl settings are defined through files in # /usr/lib/sysctl.d/, /run/sysctl.d/, and /etc/sysctl.d/. # # Vendors settings live in /usr/lib/sysctl.d/. # To override a whole file, create a new file with the same in # /etc/sysctl.d/ and put new settings there. To override # only specific settings, add a file with a lexically later # name in /etc/sysctl.</description></item><item><title/><link>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/04-ovs%E6%A1%A5%E4%B8%8EVXLAN%E9%9A%A7%E9%81%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/04-ovs%E6%A1%A5%E4%B8%8EVXLAN%E9%9A%A7%E9%81%93/</guid><description>vxlan本身支持隧道。
其配置方式与GRE隧道基本相同，只是指定interface时type=vxlan，其他的都相同。
环境准备 Host1作为网关 # 开启内核转发 [root@centos7-1 ~]# vi /etc/sysctl.conf # sysctl settings are defined through files in # /usr/lib/sysctl.d/, /run/sysctl.d/, and /etc/sysctl.d/. # # Vendors settings live in /usr/lib/sysctl.d/. # To override a whole file, create a new file with the same in # /etc/sysctl.d/ and put new settings there. To override # only specific settings, add a file with a lexically later # name in /etc/sysctl.d/ and put new settings there.</description></item><item><title/><link>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/05-%E5%AE%9E%E7%8E%B0Floating-IP/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://note.ljzsdut.com/%E7%BD%91%E7%BB%9C/05-%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96-linuxBridge-ovs-netns-vethPair/05-%E5%AE%9E%E7%8E%B0Floating-IP/</guid><description>拓补图 说明：node2和node3都处于内网环境。无法访问外网。node1是接入到公网的。如果需要访问外网，则需要使用node1上的路由设备配置SNAT规则，也可以通过为某个虚拟机分配Floating IP。
上图中，不要打通node1和node2的隧道，否则3个node会形成二层环路，造成广播风暴。
环境准备（可选） 如果node2和node3不需要连接公网下载软件，则可以不进行该步骤。
Host1作为网关 # 开启内核转发 [root@centos7-1 ~]# vi /etc/sysctl.conf # sysctl settings are defined through files in # /usr/lib/sysctl.d/, /run/sysctl.d/, and /etc/sysctl.d/. # # Vendors settings live in /usr/lib/sysctl.d/. # To override a whole file, create a new file with the same in # /etc/sysctl.d/ and put new settings there. To override # only specific settings, add a file with a lexically later # name in /etc/sysctl.</description></item></channel></rss>